# Awesome-Omni-Large-Models-and-Datasets[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
ğŸ”¥ Omni large models and datasets for understanding and generating multi-modalities.

- [Awesome-Omni-Large-Models-and-Datasets[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)](#awesome-omni-large-models-and-datasets---awesome--https---awesomere-badgesvg---https---awesomere-)
  * [ğŸ˜Models](#--models)
    + [ğŸ—’ï¸ Taxonomy](#----taxonomy)
    + [ğŸ•¹ï¸ Modality Understanding](#----modality-understanding)
  * [ğŸŒŸ Star History](#---star-history)

<small><i><a href='http://ecotrust-canada.github.io/markdown-toc/'>Table of contents generated with markdown-toc</a></i></small>

## ğŸ˜Models
### ğŸ—’ï¸ Taxonomy
 <!-- arxiv: [![arXiv](https://img.shields.io/badge/arXiv-2406.09272-b31b1b.svg?style=plastic)]()
  -->
### ğŸ•¹ï¸ Modality Understanding
<!-- ç¬¦å·:
âˆš &#10003;
x &#10007;

     å¾½ç« 
         arxiv: https://img.shields.io/badge/arXiv-2410.12109-b31b1b.svg?style=plastic
         conference: https://img.shields.io/badge/CVPR-2024-blue.svg?style=plastic
-->

<!-- æ¨¡ç‰ˆï¼š
|** ** [![arXiv](https://img.shields.io/badge/arXiv-[]-b31b1b.svg?style=plastic)](https://arxiv.org/abs/[])|**OMCAT** [![](https://img.shields.io/badge/Github-181717?style=plastic&logo=github&logoColor=white)](https://om-cat.github.io.)|Unpublished|&#10003;|&#10003;|&#10003;|&#10003;|
 -->
|Title|Model|Checkpoint|Text|Image|Audio|Video|
|:---------| :-----: | :-----: | :----: | :-----: |:-----: |:----: |
|**OMCAT: Omni Context Aware Transformer** [![arXiv](https://img.shields.io/badge/arXiv-2410.12109-b31b1b.svg?style=plastic)](https://arxiv.org/abs/2410.12109)|**OMCAT** [![](https://img.shields.io/badge/Github-181717?style=plastic&logo=github&logoColor=white)](https://om-cat.github.io.)|Unpublished|&#10003;|&#10003;|&#10003;|&#10003;|
|**VAST: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and Dataset** [![NeurIPS](https://img.shields.io/badge/NeurIPS-2023-blue.svg?style=plastic)](http://arxiv.org/abs/2305.18500)|**VAST** [![](https://img.shields.io/badge/Github-181717?style=plastic&logo=github&logoColor=white)](https://github.com/TXH-mercury/VAST)|[Github Link](https://github.com/TXH-mercury/VAST)|&#10003;|&#10003;|&#10003;|&#10003;|

## âœ¨ï¸Datasets
<!-- æ¨¡ç‰ˆï¼š
|**[æ•°æ®é›†åå­—]**|é“¾æ¥|&#10007;|&#10007;|&#10003;|æè¿°|
 -->
|Name|Link|Audio-Image-Text|Speech-Video-Text|Audio-Video-Text|Detail|
|:--------- |:----:| :-----: |:-----: |:----:|:----:|
|**OCTAV**|[Unpublished](https://om-cat.github.io.)|&#10007;|&#10007;|&#10003;|OCTAV-ST has **127,507** unique videos with single QA pairs;<br>OCTAV-MT **25,457** unique videos with a total of **180,916** QA pairs.|
|**VAST-27M**|**VAST** [![](https://img.shields.io/badge/Github-181717?style=plastic&logo=github&logoColor=white)](https://github.com/TXH-mercury/VAST)|&#10007;|&#10007;|&#10003;|27M Clips;<br>297M Captions.|

## ğŸŒŸ Star History
[![Star History Chart](https://api.star-history.com/svg?repos=LJungang/Awesome-Omni-Large-Models-and-Datasets&type=Date)](https://star-history.com/#LJungang/Awesome-Omni-Large-Models-and-Datasets&Date)

## â™¥ï¸ Contributors

<a href="https://github.com/LJungang/Awesome-Omni-Large-Models-and-Datasets/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=LJungang/Awesome-Omni-Large-Models-and-Datasets" />
</a>
